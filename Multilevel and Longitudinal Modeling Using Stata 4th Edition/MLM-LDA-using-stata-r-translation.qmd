---
title: "Multilevel and Longtudinal Modelling Using R"
subtitle: "R translation of Skrondal and Hsketh book"
author: "Abdullah"
format: html
editor: visual
---

```{r}
#|label: packages

pacman::p_load(
  haven,
  tidyverse,
  gt,
  gtsummary,
  modelsummary,
  marginaleffects,
  fixest,
  rstatix,
  easystats,
  ggdist, # To show distributions
  broom,
  DataExplorer,
  finalfit,
  skimr,
  sandwich,
  estimatr,
  equatiomatic
)
```


# Preface

Notes from the preface:

-   Don't forget to use the answers and errata to guide you through working with the book.

# Chapter 1: Review of linear regression

## 1.2 Is there gender discrimination in faculty salaries?

```{r}
#| label: load data
faculty <- read_dta("https://www.stata-press.com/data/mlmus4/faculty.dta")
faculty2 <- faculty |> 
  mutate(marketc = market - mean(market))
```


```{r}
#| label: descriptive stats 

faculty |> 
  group_by(male) |> 
  rstatix::get_summary_stats(salary)

t.test(salary ~ male, faculty)

```



```{r}
#| label: boxplots and histograms to assess normality

faculty |> 
  ggplot(aes(x = as_factor(male), y= salary)) + geom_boxplot() + coord_flip() + geom_jitter(width=0.25, alpha=0.5)

faculty |> 
  ggplot(aes(x = as_factor(male), y= log10(salary))) + geom_boxplot() + coord_flip() + geom_jitter(width=0.25, alpha=0.5)

# Histogram with counts
faculty |> 
  ggplot(aes(x = salary, fill = as.factor(male))) + geom_histogram() + facet_grid(vars(male))

# Histogram with density
faculty |> 
  ggplot(aes(x = salary, fill = as.factor(male))) + 
  geom_histogram(aes(y = ..density..),color = 1, bins = 50) + 
  facet_grid(vars(male))

faculty |> 
  ggplot(aes(x = log10(salary), fill = as.factor(male))) + 
  geom_histogram(aes(y = ..density..),color = 1, bins = 50) + 
  facet_grid(vars(male))
```

## 1.3 Independent-sample t test

```{r}
#| label: t-test

# The t-tests results are numerically consistent with STATA
t.test(salary ~ male, faculty, var.equal = F) |> tidy()
t.test(salary ~ male, faculty, var.equal = T) |> tidy()
t.test(salary ~ male, faculty, var.equal = F) |> report() 
t.test(salary ~ male, faculty, var.equal = T) |> report()

lm(salary~ as_factor(male), data =faculty) |> 
  tidy(conf.int = T)

# Give similar results to STATA margins package
lm(salary~ as_factor(male)-1, data =faculty) |> 
  tidy(conf.int = T)
```


## 1.4 One-way analysis of variance (ANOVA)
 The RMSE value here is different than the one in STATA
```{r}
#| label: anova

anova(lm(salary~ as_factor(male), data =faculty) )
performance(lm(salary~ as_factor(male), data =faculty) )
modelsummary(lm(salary~ male, data =faculty) )
```

The chunk below shows to how get the estimates using the model with `predictions()`. The really cool thing is that this is identical with the Stata output. Also, the 95% CI are shown to be different between different commands even within STATA itself.

```{r}
#| label: adjusted predictions
lm(salary~ male, data =faculty) |> 
  predictions(newdata = datagrid(male = c(0,1)))

```


## 1.5 Simple linear regression

```{r}
# Explore marketability
# Summary stats
faculty |> 
  skim(market)

faculty |> distinct(market) |> nrow() #distinct values

# Scatter plot (Figure 1.4)
faculty |> 
  ggplot(aes(x = market, y = salary)) + geom_point() + geom_smooth(method = "loess", se = F) + geom_smooth(method = "lm", color = "red", se = F)

# Simple linear regression
lm(salary ~ market, data = faculty) |> 
  tidy(conf.int = T)
lm(salary ~ market, data = faculty) |>
  performance()
# Centering market and refitting the model
lm(salary ~ marketc, data = faculty |> mutate(marketc = market - mean(market))) |> 
  augment(data = faculty) |> 
  ggplot(aes(x = market, y = salary)) + geom_point()+  geom_smooth(method = "lm", se = F) +
  geom_line(aes(x = market, y = .fitted), color = "darkgreen")
  tidy(conf.int = T)

# Plotting simple linear regression

```


## 1.6 Dummy variables

Good to know: A simple linear regression y~x, where y is a continuous outcome and x is an explanatory binary variable, is equivalent to a t-test with equal variance because equal variance is the same as the homosckedasticity assumption in regression.

t-test with unequal variance == simple linear regression y~x with correcting SEs for heterosckedasiticity

```{r}
# Simple linear regression
lm(salary ~ male, data = faculty) |> 
  tidy(conf.int = T)
lm(salary ~ market, data = faculty) |>
  performance()

# One way to calculate standard errors and make them robust against heteroskecdasitity (unequal variance)
feols(salary ~ male, data = faculty) |> 
  tidy(conf.int = T, se = "hetero")
```

## 1.7 Multiple linear regression

```{r}
faculty |> 
  mutate(marketc = market - mean(market)) |> 
  group_by(male) |> 
  rstatix::get_summary_stats(marketc)

faculty |> 
  mutate(marketc = market - mean(market)) |> 
  summary()
```


```{r}
faculty2 <- faculty |> 
  mutate(marketc = market - mean(market))

faculty2 |>   ggplot(aes(x= marketc, y = salary, color = as_factor(male))) + geom_point() + geom_smooth(method = "lm", se = F)

lm(salary ~ marketc + male, data = faculty2) |>
  predictions() |> 
  ggplot(aes(x= marketc, y = predicted, color = as_factor(male))) +  geom_smooth(method = "lm", se = F) +
  geom_point(aes(y=salary))
  
```

```{r}
#| label: model
lm(salary ~ marketc + male, data = faculty2) |> tidy(conf.int = T)
lm(salary ~ marketc + male, data = faculty2) |> anova()
olsrr::ols_regress(salary ~ marketc + male, data = faculty2) 

```


```{r}
faculty2 |> 
  ggplot(aes(marketc, color = as_factor(male))) + geom_density()
```

```{r}
#| label: Adding years since degree to the model

lm(salary ~ marketc + male + yearsdg, data = faculty2) |> tidy(conf.int = T)

# Estimate the predicted mean estimates of the two genders based on yearsdg = 10, marketc = 0
lm(salary~ marketc + male + yearsdg, data =faculty2) |> 
  predictions(newdata = datagrid(male = c(0,1), yearsdg = 10, marketc = 0))

lm(salary~ marketc + male + yearsdg, data =faculty2) |> 
  predictions(newdata = datagrid(male = c(0,1)))
```

# 1.8 Interactions

```{r}
lm(salary ~ marketc + male *yearsdg, data = faculty2) |> tidy(conf.int = T)
lm(salary ~ marketc + male *yearsdg, data = faculty2) |> extract_eq()
```
$$
\operatorname{salary} = \alpha + \beta_{1}(\operatorname{marketc}) + \beta_{2}(\operatorname{male}) + \beta_{3}(\operatorname{yearsdg}) + \beta_{4}(\operatorname{male} \times \operatorname{yearsdg}) + \epsilon
$$

The chunk below gives the same estimate, standard error, t statisic, p.value, but they give slightly different confidence interval. wondering why?
```{r}
library(tidyverse)
library(marginaleffects)
library(haven)

faculty <- read_dta("https://www.stata-press.com/data/mlmus4/faculty.dta")
faculty2 <- faculty |>
  mutate(marketc = market - mean(market))

lm(salary~ marketc + male *yearsdg, data =faculty2) |> 
  comparisons(
    variables = list(male = c(0,1)),
    newdata = datagrid(yearsdg = 10))

```


```{r}
#| label: Plot interaction (Figure 1.14)
lm(salary~ marketc + male *yearsdg, data =faculty2) |> 
  predictions(variables = list(male = c(0,1), marketc = 0)) |> 
  ggplot(aes(x = yearsdg, y = predicted, linetype = as_factor(male))) + geom_line() +scale_linetype_manual(values=c("dashed", "solid")) +
  theme(legend.position = "bottom")
```


# 1.9 Dummy variables for more than two groups

```{r}
faculty3 <- faculty2 |> 
  mutate(rank2 = as_factor(rank))

# Basic model
lm(salary~ rank2, data =faculty3) |> tidy(conf.int = T)

# Get estimates for each rank with the corresponding 95% CI
lm(salary~ rank2-1, data =faculty3) |> tidy(conf.int = T)


# Full vs Associate
lm(salary~ rank2, data =faculty3)|> 
  comparisons(
    variables = list(rank2 = "pairwise")) |>  tidy()

# ANOVA
anova(lm(salary~ rank2, data =faculty3))

# Partial F tests (Equivalent to Stata's testparm command)
full_model <- lm(salary~ marketc + male *yearsdg + rank2, data =faculty3)
reduced_model <- lm(salary~ marketc + male *yearsdg , data =faculty3)
anova(reduced_model, full_model)

# Show the full model
full_model |> tidy(conf.int =T)
reduced_model |> tidy(conf.int =T)
full_model |> extract_eq(coef_digits = 2, use_coefs = T)

# Using full model, provide the estimated difference in mean salary between male vs female at 10 years since degree
full_model |> 
  comparisons(
    variables = list(male = c(0,1)),
    newdata = datagrid(yearsdg = 10)
  )
```
$$
\operatorname{\widehat{salary}} = 37493.09 + 36987.08(\operatorname{marketc}) - 1043.39(\operatorname{male}) + 405.27(\operatorname{yearsdg}) + 3349.01(\operatorname{rank2}_{\operatorname{Associate}}) + 11168.26(\operatorname{rank2}_{\operatorname{Full}}) + 184.38(\operatorname{male} \times \operatorname{yearsdg})
$$


# 1.10 Other types of interactions

## Interaction between dummy variables

This is equivalent to two-way ANOVA

```{r}
lm(salary~ marketc + male*rank2 +yearsdg, data =faculty3) |> tidy(conf.int =T)
lm(salary~ marketc + male*rank2 +yearsdg, data =faculty3)|> extract_eq(coef_digits = 2, use_coefs = F,terms_per_line = 3,
                                                                        wrap = T)
```
$$
\begin{aligned}
\operatorname{salary} &= \alpha + \beta_{1}(\operatorname{marketc}) + \beta_{2}(\operatorname{male})\ + \\
&\quad \beta_{3}(\operatorname{rank2}_{\operatorname{Associate}}) + \beta_{4}(\operatorname{rank2}_{\operatorname{Full}}) + \beta_{5}(\operatorname{yearsdg})\ + \\
&\quad \beta_{6}(\operatorname{male} \times \operatorname{rank2}_{\operatorname{Associate}}) + \beta_{7}(\operatorname{male} \times \operatorname{rank2}_{\operatorname{Full}}) + \epsilon
\end{aligned}
$$

- Interaction between dummy variables can be interpreted as difference of difference


```{r}
# Partial F tests (Equivalent to Stata's testparm command) to test for interaction terms
full_model <- lm(salary~ marketc + male +yearsdg + rank2, data =faculty3)
reduced_model <- lm(salary~ marketc + male*rank2 +yearsdg , data =faculty3)
anova(reduced_model, full_model)
```


## Interaction between continuous covariates

```{r}
lm(salary~ marketc*yearsdg + male+rank2, data =faculty3) |> tidy(conf.int =T)
lm(salary~ marketc*yearsdg + male+rank2, data =faculty3)|> extract_eq(coef_digits = 2, use_coefs = F,terms_per_line = 3,
                                                                        wrap = T)
```

# 1.11 Non linear effects

```{r}
lm(salary~ yearsdg*(marketc+male)+ I(yearsdg^2) + rank2, data =faculty3) |> tidy(conf.int =T)
lm(salary~ yearsdg*(marketc+male)+ I(yearsdg^2) + rank2, data =faculty3) |> 
  predictions(variables = list(male = c(0,1), marketc = 0, rank2 = "Assistant")) |> 
  ggplot(aes(x = yearsdg, y = predicted, linetype = as_factor(male))) + geom_line() +scale_linetype_manual(values=c("dashed", "solid")) +
  theme(legend.position = "bottom")
```

# 1.12 Residual diagnostics

Useful to check homosckedaticity and normal distribution of errors

```{r}
lm(salary~ yearsdg*(marketc+male)+ I(yearsdg^2) + rank2, data =faculty3) |> check_model()
```

